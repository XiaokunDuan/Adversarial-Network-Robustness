<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Adversarial Robustness in 3D Point Clouds | Adversarial Network & Robustness</title><meta name=keywords content="robustness,adversarial-learning"><meta name=description content="Motivation
Transformer-based LLMs and other trendy NNs has achieve significant successes. It seems like the power of AI dominates almost every field. The efficiency and accuracy outnumber the human intelligence completely. The human last exam, including various difficult intelligence puzzles, has beaten by AI recently at a extremely high level.
However, the seemingly powerful tools demonstrates staggering fragility when facing a small disturbance. [example]
[fig]
These treats can be classified into several categories.[classes][fig]"><meta name=author content="Xiaokun Duan"><link rel=canonical href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/posts/2025-09-08-adversary-robustness/><link crossorigin=anonymous href=/XiaokunDuan/Adversarial-Network-Robustness/assets/css/stylesheet.e8f0ac3d1006ba094c176f61e657abbab7e1e22c80e56513abbd5be5e6a566f2.css integrity="sha256-6PCsPRAGuglMF29h5lerurfh4iyA5WUTq71b5ealZvI=" rel="preload stylesheet" as=style><link rel=icon href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/favicon-32x32.png><link rel=apple-touch-icon href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/apple-touch-icon.png><link rel=mask-icon href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/posts/2025-09-08-adversary-robustness/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><meta property="og:url" content="https://github.com/XiaokunDuan/Adversarial-Network-Robustness/posts/2025-09-08-adversary-robustness/"><meta property="og:site_name" content="Adversarial Network & Robustness"><meta property="og:title" content="Adversarial Robustness in 3D Point Clouds"><meta property="og:description" content="Motivation Transformer-based LLMs and other trendy NNs has achieve significant successes. It seems like the power of AI dominates almost every field. The efficiency and accuracy outnumber the human intelligence completely. The human last exam, including various difficult intelligence puzzles, has beaten by AI recently at a extremely high level.
However, the seemingly powerful tools demonstrates staggering fragility when facing a small disturbance. [example] [fig]
These treats can be classified into several categories.[classes][fig]"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-09-08T00:00:00+00:00"><meta property="article:modified_time" content="2025-09-08T00:00:00+00:00"><meta property="article:tag" content="Robustness"><meta property="article:tag" content="Adversarial-Learning"><meta name=twitter:card content="summary"><meta name=twitter:title content="Adversarial Robustness in 3D Point Clouds"><meta name=twitter:description content="Motivation
Transformer-based LLMs and other trendy NNs has achieve significant successes. It seems like the power of AI dominates almost every field. The efficiency and accuracy outnumber the human intelligence completely. The human last exam, including various difficult intelligence puzzles, has beaten by AI recently at a extremely high level.
However, the seemingly powerful tools demonstrates staggering fragility when facing a small disturbance. [example]
[fig]
These treats can be classified into several categories.[classes][fig]"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://github.com/XiaokunDuan/Adversarial-Network-Robustness/posts/"},{"@type":"ListItem","position":2,"name":"Adversarial Robustness in 3D Point Clouds","item":"https://github.com/XiaokunDuan/Adversarial-Network-Robustness/posts/2025-09-08-adversary-robustness/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Adversarial Robustness in 3D Point Clouds","name":"Adversarial Robustness in 3D Point Clouds","description":"Motivation Transformer-based LLMs and other trendy NNs has achieve significant successes. It seems like the power of AI dominates almost every field. The efficiency and accuracy outnumber the human intelligence completely. The human last exam, including various difficult intelligence puzzles, has beaten by AI recently at a extremely high level.\nHowever, the seemingly powerful tools demonstrates staggering fragility when facing a small disturbance. [example] [fig]\nThese treats can be classified into several categories.[classes][fig]\n","keywords":["robustness","adversarial-learning"],"articleBody":"Motivation Transformer-based LLMs and other trendy NNs has achieve significant successes. It seems like the power of AI dominates almost every field. The efficiency and accuracy outnumber the human intelligence completely. The human last exam, including various difficult intelligence puzzles, has beaten by AI recently at a extremely high level.\nHowever, the seemingly powerful tools demonstrates staggering fragility when facing a small disturbance. [example] [fig]\nThese treats can be classified into several categories.[classes][fig]\nWhy robustness matters?\nThe treats can be pretty sensitive under circumstances of self-driving, medical inspect and military affairs.[example][fig]\nAdversarial Training and Empirical Defenses A classic paradox is that what happens when an unstoppable force meets an immovable object?\n[limitations]\n(Zhang et al., 2023) Left columns are original point cloud, while the right columns are disturbed slightly. The model falls into Type I and Type II errors. Image source: (Altekrüger et al., 2024)\nBelow is the literature review concentrating on 3D point clouds.[literature review]\nTargeted removal：An adversarial attack can identify the most critical points for a 3D detector using a gradient-based saliency map. By strategically removing just these few key points, the attack effectively sabotages the model’s perception.\nAn example of a targeted removal attack.\nObjective function: $X^a$ is adversarial example. $D$ is $L_2$ norm. $$ \\min J(X^a, G) = -L_{det}(X^a, G) + \\lambda D(X, X^a) $$ Iterative Attack Update Rule: $$ X_a^{t+1} = \\text{Clip}_{X, \\epsilon} \\left\\{ X_a^t - \\alpha \\frac{\\nabla_{X_a^t} J(X_a^t, G)}{|\\nabla_{X_a^t} J(X_a^t, G)|_2} \\right\\} $$ Visualization of the iterative attack update process.\nAdverasril training: balace training from my point of view $$ L_{total} = w_{clean} \\times L_{clean} + w_{adv} \\times L_{adv} $$ Quality dataset behaves strong robustness:\nAccuracy vs. Robustness plot for different 3D object detectors.\nKey takeway:Accuracy ≠ Robustness: High accuracy does not guarantee high robustness. Voxel-based models are stronger: Red markers cluster in the top-right, showing better overall performance. Because of gradient disruption and homogeneous perturbation.（rasterization /pixelization）\nHowever, we cannot conclusively state that voxel-based detectors are more robust.\nPlot Explanation – X-axis (Clean mAP): Model accuracy on clean data. Further right is better. Y-axis (mAP Ratio): Model robustness under attack. Higher is better. Colors: Red = voxel-based, Green = point-based, Yellow = point-voxel hybrid. Marker Size: Represents the network size (more parameters).\nTheoretical viewpoint: From Empirical Defenses to Provable Robustness [from math perspective]\nUnstable jump: Learning the entire posterior distribution is more robust than using point estimates (like the MAP estimator). Deep learning models learn the posterior distribution by minimizing a loss function that is averaged over the entire training dataset. But good performance on average does not guarantee good performance at a single, specific point that we actually care about in practice. (Altekrüger et al., 2024) provides the first theoretical link, proving that if the average loss is sufficiently small, then the performance at a single point can also be guaranteed.\nImage source: (Altekrüger et al., 2024)\nProof logic: $$ W_1(P_{X|Y=\\tilde{y}}, G_{\\theta}(\\tilde{y}, \\cdot)_{\\#}P_Z) \\le C\\epsilon^{\\frac{1}{n+1}} $$ LHS is the $W_1$ difference between two distribution. RHS is the upper bound of certification.\nConceptual flow of the proof for establishing a robustness certificate.\nFirst, because the model’s average error across all possible data is known to be small, it is impossible for the error to be large everywhere; this guarantees the existence of at least one “well-behaved” point, $\\hat{y}$, within a small neighborhood of our specific target point, $\\tilde{y}$, where the local error is also provably small. Second, the crucial property of Lipschitz continuity is leveraged, which ensures the system is smooth and prevents abrupt changes. This means that since $\\tilde{y}$ and $\\hat{y}$ are physically close, the error at $\\tilde{y}$ cannot be drastically different from the error at $\\hat{y}$. Finally, by combining the known small error at the “well-behaved” point $\\hat{y}$ with the bounded change in error between $\\hat{y}$ and $\\tilde{y}$, the proof establishes a definitive upper bound on the model’s error at the single, specific point $\\tilde{y}$ that we care about.\n[theoretical path]\nThe core conflict persists in the research field is the trade-off between model accuracy and robustness.\nWrap-up of robustness The measurement of robustness The essence of robustness trade-off The boundary of robustness (Enomoto, 2024) Shannon Entropy： $$ H = - \\sum_{y=1}^{C} \\hat{p}(y|x) \\log \\hat{p}(y|x) $$\nThe hardest clean examples (i.e., those with high entropy) are as difficult for the model as the easiest augmented examples. The change is continuous rather than a leap.![comparision of samples](./comparision of samples-7487819.png)\nEntProp treats the augmented sample as in-distribution domain and feeds it to MBN (orange bracket ). EntProp then adversarial attacks high-entropy samples and feeds it to ABN (blue bracket ). For CIFAR10, the analysis results in an upper bound (of certified robust accuracy) of 67.49%, meanwhile existing approaches are only able to increase it from 53.89% in 2017 to 62.84% in 2023.\nVisualization of the two different trainning.\nThe Demand for Robustness: We require that a model’s prediction remains constant within a local neighborhood ($\\mathcal{V}_x$) around each data point $x$. The convolution process inherently increases the overlap between class distributions, making the problem harder. Therefore, the Bayes error of the new distribution is greater than or equal to that of the original. This requirement effectively changes the target data distribution. The problem is no longer about fitting the original distribution $\\mathcal{D}$.\nThe pursuit of certified robustness forces us to optimize for a new, inherently harder problem ($\\mathcal{D’}$) that has a higher minimum error rate. This establishes a fundamental theoretical limit on certified robust accuracy, explaining why it is inevitably lower than standard accuracy.\nCurrent Challenges Future Works References [1]Zhang, Y., Hou, J., \u0026 Yuan, Y. \"A Comprehensive Study of the Robustness for LiDAR-based 3D Object Detectors against Adversarial Attacks\" arXiv preprint arXiv:2212.10230 (2023). [2]Altekrüger, F., Hagemann, P., \u0026 Steidl, G. \"Conditional Generative Models Are Provably Robust: Pointwise Guarantees for Bayesian Inverse Problems\" arXiv preprint arXiv:2303.15845 (2024). [3]Enomoto, S. \"EntProp: High Entropy Propagation for Improving Accuracy and Robustness\" arXiv preprint arXiv:2405.18931 (2024). ","wordCount":"977","inLanguage":"en","datePublished":"2025-09-08T00:00:00Z","dateModified":"2025-09-08T00:00:00Z","author":{"@type":"Person","name":"Xiaokun Duan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://github.com/XiaokunDuan/Adversarial-Network-Robustness/posts/2025-09-08-adversary-robustness/"},"publisher":{"@type":"Organization","name":"Adversarial Network \u0026 Robustness","logo":{"@type":"ImageObject","url":"https://github.com/XiaokunDuan/Adversarial-Network-Robustness/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/ accesskey=h title="Adversarial Network & Robustness (Alt + H)">Adversarial Network & Robustness</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Adversarial Robustness in 3D Point Clouds</h1><div class=post-meta>Date: September 8, 2025&nbsp;&nbsp;|&nbsp;&nbsp;Estimated Reading Time: 5 min&nbsp;&nbsp;|&nbsp;&nbsp;Author: Xiaokun Duan</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#motivation aria-label=Motivation>Motivation</a></li><li><a href=#adversarial-training-and-empirical-defenses aria-label="Adversarial Training and Empirical Defenses">Adversarial Training and Empirical Defenses</a></li><li><a href=#theoretical-viewpoint-from-empirical-defenses-to-provable-robustness aria-label="Theoretical viewpoint: From Empirical Defenses to Provable Robustness">Theoretical viewpoint: From Empirical Defenses to Provable Robustness</a></li><li><a href=#wrap-up-of-robustness aria-label="Wrap-up of robustness">Wrap-up of robustness</a><ul><li><a href=#the-measurement-of-robustness aria-label="The measurement of robustness">The measurement of robustness</a></li><li><a href=#the-essence-of-robustness-trade-off aria-label="The essence of robustness trade-off">The essence of robustness trade-off</a></li><li><a href=#the-boundary-of-robustness aria-label="The boundary of robustness">The boundary of robustness</a></li></ul></li><li><a href=#current-challenges aria-label="Current Challenges">Current Challenges</a></li><li><a href=#future-works aria-label="Future Works">Future Works</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><h1 id=motivation>Motivation<a hidden class=anchor aria-hidden=true href=#motivation>#</a></h1><p>Transformer-based LLMs and other trendy NNs has achieve significant successes. It seems like the power of AI dominates almost every field. The efficiency and accuracy outnumber the human intelligence completely. The human last exam, including various difficult intelligence puzzles, has beaten by AI recently at a extremely high level.</p><p>However, the seemingly powerful tools demonstrates staggering fragility when facing a small disturbance. [example]
[fig]</p><p>These treats can be classified into several categories.[classes][fig]</p><p>Why robustness matters?</p><p>The treats can be pretty sensitive under circumstances of self-driving, medical inspect and military affairs.[example][fig]</p><h1 id=adversarial-training-and-empirical-defenses>Adversarial Training and Empirical Defenses<a hidden class=anchor aria-hidden=true href=#adversarial-training-and-empirical-defenses>#</a></h1><p>A classic paradox is that what happens when an unstoppable force meets an immovable object?</p><figure class=figure-medium><img loading=lazy src=unstoppable-force-immovable-object.png></figure><p>[limitations]</p><a href=#ref-zhangComprehensiveStudyRobustness2023 class=in-text-citation>(Zhang et al., 2023)</a><figure><img loading=lazy src=adversarial-point-cloud-examples.png alt="Left columns are original point cloud, while the right columns are disturbed slightly. The model falls into Type I and Type II errors. Image source: (Altekrüger et al., 2024)"><figcaption><p>Left columns are original point cloud, while the right columns are disturbed slightly. The model falls into Type I and Type II errors. Image source: <a href=#ref-altekrugerConditionalGenerativeModels2024 class=in-text-citation>(Altekrüger et al., 2024)</a></p></figcaption></figure><p>Below is the literature review concentrating on 3D point clouds.[literature review]</p><p>Targeted removal：An adversarial attack can identify the most critical points for a 3D detector using a gradient-based saliency map. By strategically removing just these few key points, the attack effectively sabotages the model&rsquo;s perception.</p><figure><img loading=lazy src=targeted-removal-attack.png alt="An example of a targeted removal attack."><figcaption><p>An example of a targeted removal attack.</p></figcaption></figure><p><strong>Objective function:</strong> $X^a$ is adversarial example. $D$ is $L_2$ norm.
$$
\min J(X^a, G) = -L_{det}(X^a, G) + \lambda D(X, X^a)
$$
<strong>Iterative Attack Update Rule</strong>:
$$
X_a^{t+1} = \text{Clip}_{X, \epsilon} \left\{ X_a^t - \alpha \frac{\nabla_{X_a^t} J(X_a^t, G)}{|\nabla_{X_a^t} J(X_a^t, G)|_2} \right\}
$$<figure><img loading=lazy src=iterative-attack-visualization.png alt="Visualization of the iterative attack update process."><figcaption><p>Visualization of the iterative attack update process.</p></figcaption></figure></p><p><strong>Adverasril training:</strong> balace training from my point of view
$$
L_{total} = w_{clean} \times L_{clean} + w_{adv} \times L_{adv}
$$
<strong>Quality dataset behaves strong robustness:</strong></p><figure><img loading=lazy src=accuracy-vs-robustness-plot.png alt="Accuracy vs. Robustness plot for different 3D object detectors."><figcaption><p>Accuracy vs. Robustness plot for different 3D object detectors.</p></figcaption></figure><p><strong>Key takeway</strong>:Accuracy ≠ Robustness: High accuracy does not guarantee high robustness. Voxel-based models are stronger: Red markers cluster in the top-right, showing better overall performance. Because of gradient disruption and homogeneous perturbation.（rasterization /pixelization）</p><p><strong>However, we cannot conclusively state that voxel-based detectors are more robust.</strong></p><figure class=figure-medium><img loading=lazy src=model-performance-comparison.png alt="Plot Explanation &ndash; X-axis (Clean mAP): Model accuracy on clean data. Further right is better. Y-axis (mAP Ratio): Model robustness under attack. Higher is better. Colors: Red = voxel-based, Green = point-based, Yellow = point-voxel hybrid. Marker Size: Represents the network size (more parameters)."><figcaption><p>Plot Explanation &ndash; X-axis (Clean mAP): Model accuracy on clean data. Further right is better. Y-axis (mAP Ratio): Model robustness under attack. Higher is better. Colors: Red = voxel-based, Green = point-based, Yellow = point-voxel hybrid. Marker Size: Represents the network size (more parameters).</p></figcaption></figure><h1 id=theoretical-viewpoint-from-empirical-defenses-to-provable-robustness>Theoretical viewpoint: From Empirical Defenses to Provable Robustness<a hidden class=anchor aria-hidden=true href=#theoretical-viewpoint-from-empirical-defenses-to-provable-robustness>#</a></h1><p>[from math perspective]</p><p><strong>Unstable jump</strong>: Learning the entire posterior distribution is more robust than using point estimates (like the MAP estimator). Deep learning models learn the posterior distribution by minimizing a loss function that is averaged over the entire training dataset. But <strong>good performance <em>on average</em> does not guarantee good performance at a <em>single, specific point</em> that we actually care about in practice.</strong> <a href=#ref-altekrugerConditionalGenerativeModels2024 class=in-text-citation>(Altekrüger et al., 2024)</a> provides the first theoretical link, proving that if the average loss is sufficiently small, then the performance at a single point can also be guaranteed.</p><figure><img loading=lazy src=theoretical-robustness-certificate.png alt="Image source: (Altekrüger et al., 2024)"><figcaption><p>Image source: <a href=#ref-altekrugerConditionalGenerativeModels2024 class=in-text-citation>(Altekrüger et al., 2024)</a></p></figcaption></figure><p><strong>Proof logic</strong>:
$$
W_1(P_{X|Y=\tilde{y}}, G_{\theta}(\tilde{y}, \cdot)_{\#}P_Z) \le C\epsilon^{\frac{1}{n+1}}
$$
LHS is the $W_1$ difference between two distribution. RHS is the upper bound of certification.</p><figure><img loading=lazy src=proof-logic-flow.png alt="Conceptual flow of the proof for establishing a robustness certificate."><figcaption><p>Conceptual flow of the proof for establishing a robustness certificate.</p></figcaption></figure><p>First, because the model&rsquo;s average error across all possible data is known to be small, it is impossible for the error to be large everywhere; this guarantees the existence of at least one &ldquo;well-behaved&rdquo; point, $\hat{y}$, within a small neighborhood of our specific target point, $\tilde{y}$, where the local error is also provably small. Second, the crucial property of Lipschitz continuity is leveraged, which ensures the system is smooth and prevents abrupt changes. This means that since $\tilde{y}$ and $\hat{y}$ are physically close, the error at $\tilde{y}$ cannot be drastically different from the error at $\hat{y}$. Finally, by combining the known small error at the &ldquo;well-behaved&rdquo; point $\hat{y}$ with the bounded change in error between $\hat{y}$ and $\tilde{y}$, the proof establishes a definitive upper bound on the model&rsquo;s error at the single, specific point $\tilde{y}$ that we care about.</p><p>[theoretical path]</p><p>The core conflict persists in the research field is the trade-off between model accuracy and robustness.</p><h1 id=wrap-up-of-robustness>Wrap-up of robustness<a hidden class=anchor aria-hidden=true href=#wrap-up-of-robustness>#</a></h1><h2 id=the-measurement-of-robustness>The measurement of robustness<a hidden class=anchor aria-hidden=true href=#the-measurement-of-robustness>#</a></h2><h2 id=the-essence-of-robustness-trade-off>The essence of robustness trade-off<a hidden class=anchor aria-hidden=true href=#the-essence-of-robustness-trade-off>#</a></h2><h2 id=the-boundary-of-robustness>The boundary of robustness<a hidden class=anchor aria-hidden=true href=#the-boundary-of-robustness>#</a></h2><a href=#ref-enomotoEntPropHighEntropy2024 class=in-text-citation>(Enomoto, 2024)</a><p><strong>Shannon Entropy</strong>：
$$
H = - \sum_{y=1}^{C} \hat{p}(y|x) \log \hat{p}(y|x)
$$</p><p>The hardest clean examples (i.e., those with high entropy) are as difficult for the model as the easiest augmented examples. The change is continuous rather than a leap.![comparision of samples](./comparision of samples-7487819.png)</p><p>EntProp treats the augmented sample as in-distribution domain and feeds it to MBN (orange bracket ). EntProp then adversarial attacks high-entropy samples and feeds it to ABN (blue bracket ). For CIFAR10, the analysis results in <strong>an upper bound (of certified robust accuracy) of 67.49%</strong>, meanwhile existing approaches are only able to increase it <strong>from 53.89% in 2017 to 62.84% in 2023</strong>.</p><figure><img loading=lazy src=EntProp.png alt="Visualization of the two different trainning."><figcaption><p>Visualization of the two different trainning.</p></figcaption></figure><p>The Demand for Robustness: We require that a model&rsquo;s prediction remains constant within a local neighborhood ($\mathcal{V}_x$) around each data point $x$. The convolution process inherently increases the overlap between class distributions, making the problem harder. Therefore, the Bayes error of the new distribution is greater than or equal to that of the original. This requirement effectively changes the target data distribution. The problem is no longer about fitting the original distribution $\mathcal{D}$.</p><p>The pursuit of certified robustness forces us to optimize for a new, inherently harder problem ($\mathcal{D&rsquo;}$) that has a higher minimum error rate. This establishes a fundamental theoretical limit on certified robust accuracy, explaining why it is inevitably lower than standard accuracy.</p><h1 id=current-challenges>Current Challenges<a hidden class=anchor aria-hidden=true href=#current-challenges>#</a></h1><h1 id=future-works>Future Works<a hidden class=anchor aria-hidden=true href=#future-works>#</a></h1><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><div class=csl-bib-body><div class=csl-entry id=ref-zhangComprehensiveStudyRobustness2023><div class=csl-left-margin>[1]</div>Zhang, Y., Hou, J., & Yuan, Y. <a href=https://doi.org/10.48550/arXiv.2212.10230 target=_blank>"A Comprehensive Study of the Robustness for LiDAR-based 3D Object Detectors against Adversarial Attacks"</a> arXiv preprint arXiv:2212.10230 (2023).</div><div class=csl-entry id=ref-altekrugerConditionalGenerativeModels2024><div class=csl-left-margin>[2]</div>Altekr&uuml;ger, F., Hagemann, P., & Steidl, G. <a href=https://doi.org/10.48550/arXiv.2303.15845 target=_blank>"Conditional Generative Models Are Provably Robust: Pointwise Guarantees for Bayesian Inverse Problems"</a> arXiv preprint arXiv:2303.15845 (2024).</div><div class=csl-entry id=ref-enomotoEntPropHighEntropy2024><div class=csl-left-margin>[3]</div>Enomoto, S. <a href=https://doi.org/10.48550/arXiv.2405.18931 target=_blank>"EntProp: High Entropy Propagation for Improving Accuracy and Robustness"</a> arXiv preprint arXiv:2405.18931 (2024).</div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/tags/robustness/>Robustness</a></li><li><a href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/tags/adversarial-learning/>Adversarial-Learning</a></li></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Adversarial Robustness in 3D Point Clouds on x" href="https://x.com/intent/tweet/?text=Adversarial%20Robustness%20in%203D%20Point%20Clouds&amp;url=https%3a%2f%2fgithub.com%2fXiaokunDuan%2fAdversarial-Network-Robustness%2fposts%2f2025-09-08-adversary-robustness%2f&amp;hashtags=robustness%2cadversarial-learning"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Adversarial Robustness in 3D Point Clouds on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fgithub.com%2fXiaokunDuan%2fAdversarial-Network-Robustness%2fposts%2f2025-09-08-adversary-robustness%2f&amp;title=Adversarial%20Robustness%20in%203D%20Point%20Clouds&amp;summary=Adversarial%20Robustness%20in%203D%20Point%20Clouds&amp;source=https%3a%2f%2fgithub.com%2fXiaokunDuan%2fAdversarial-Network-Robustness%2fposts%2f2025-09-08-adversary-robustness%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Adversarial Robustness in 3D Point Clouds on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fgithub.com%2fXiaokunDuan%2fAdversarial-Network-Robustness%2fposts%2f2025-09-08-adversary-robustness%2f&title=Adversarial%20Robustness%20in%203D%20Point%20Clouds"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Adversarial Robustness in 3D Point Clouds on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fgithub.com%2fXiaokunDuan%2fAdversarial-Network-Robustness%2fposts%2f2025-09-08-adversary-robustness%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Adversarial Robustness in 3D Point Clouds on whatsapp" href="https://api.whatsapp.com/send?text=Adversarial%20Robustness%20in%203D%20Point%20Clouds%20-%20https%3a%2f%2fgithub.com%2fXiaokunDuan%2fAdversarial-Network-Robustness%2fposts%2f2025-09-08-adversary-robustness%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Adversarial Robustness in 3D Point Clouds on telegram" href="https://telegram.me/share/url?text=Adversarial%20Robustness%20in%203D%20Point%20Clouds&amp;url=https%3a%2f%2fgithub.com%2fXiaokunDuan%2fAdversarial-Network-Robustness%2fposts%2f2025-09-08-adversary-robustness%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Adversarial Robustness in 3D Point Clouds on ycombinator" href="https://news.ycombinator.com/submitlink?t=Adversarial%20Robustness%20in%203D%20Point%20Clouds&u=https%3a%2f%2fgithub.com%2fXiaokunDuan%2fAdversarial-Network-Robustness%2fposts%2f2025-09-08-adversary-robustness%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://github.com/XiaokunDuan/Adversarial-Network-Robustness/>Adversarial Network & Robustness</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>